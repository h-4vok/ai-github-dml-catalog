# .env.example

# --- GitHub Configuration ---
# Personal Access Token with 'repo' scope is required to read organization repositories.
GITHUB_TOKEN=your_github_pat
# The name of the GitHub organization you want to scan.
GITHUB_ORG_NAME=my-awesome-org

# --- LLM Provider Configuration ---
# Choose your LLM provider. Supported values: 'ollama' or 'cloud'.
LLM_PROVIDER=ollama
# Timeout for LLM requests in milliseconds (e.g., 360000 for 6 minutes).
LLM_TIMEOUT_MS=360000

# --- Ollama Configuration (only used if LLM_PROVIDER is 'ollama') ---
# The base URL of your locally running Ollama instance.
OLLAMA_BASE_URL=http://localhost:11434
# The model tag to use with Ollama (e.g., llama3, codellama).
OLLAMA_MODEL=llama3

# --- Cloud LLM Configuration (only used if LLM_PROVIDER is 'cloud') ---
# Your API key for the cloud provider (e.g., OpenAI, Anthropic).
CLOUD_API_KEY=your_cloud_api_key
# The API endpoint for the chat completions.
CLOUD_API_URL=https://api.openai.com/v1/chat/completions
# The model identifier to use (e.g., gpt-4o, claude-3-opus-20240229).
CLOUD_MODEL=gpt-4o

# --- Scanner Configuration ---
# Comma-separated list of file extensions to scan.
SCANNER_FILE_EXTENSIONS=.php,.go,.java,.cs,.py,.rb,.js,.ts,.sql
